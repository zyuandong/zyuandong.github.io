<h1 id="python--sae">Python脚本–下载合并SAE日志</h1>

<blockquote>
  <p>由于一些原因，需要SAE上站点的日志文件，从SAE上只能按天下载，下载下来手动处理比较蛋疼，尤其是数量很大的时候。还好SAE提供了API可以批量获得日志文件下载地址，刚刚写了python脚本自动下载和合并这些文件</p>
</blockquote>

<h2 id="api">调用API获得下载地址</h2>
<p>文档位置在<a href="http://sae.sina.com.cn/?m=devcenter&amp;catId=281">这里</a></p>

<h3 id="section">设置自己的应用和下载参数</h3>
<p>请求中需要设置的变量如下</p>

<pre><code>api_url = 'http://dloadcenter.sae.sina.com.cn/interapi.php?'
appname = 'xxxxx'
from_date = '20140101'
to_date = '20140116'
url_type = 'http' # http|taskqueue|cron|mail|rdc
url_type2 = 'access' # only when type=http  access|debug|error|warning|notice|resources
secret_key = 'xxxxx'
</code></pre>

<h3 id="section-1">生成请求地址</h3>
<p>请求地址生成方式可以看一下官网的要求：</p>

<ol>
  <li>将参数排序</li>
  <li>生成请求字符串，去掉<code>&amp;</code></li>
  <li>附加access_key</li>
  <li>请求字符串求md5，形成sign</li>
  <li>把sign增加到请求字符串中</li>
</ol>

<p>具体实现代码如下</p>

<pre><code>params = dict()
params['act'] = 'log'
params['appname'] = appname
params['from'] = from_date
params['to'] = to_date
params['type'] = url_type

if url_type == 'http':
    params['type2'] = url_type2

params = collections.OrderedDict(sorted(params.items()))

request = ''
for k,v in params.iteritems():
    request += k+'='+v+'&amp;'

sign = request.replace('&amp;','')
sign += secret_key

md5 = hashlib.md5()
md5.update(sign)
sign = md5.hexdigest()

request = api_url + request + 'sign=' + sign

if response['errno'] != 0:
    print '[!] '+response['errmsg']
    exit()

print '[#] request success'
</code></pre>

<h2 id="section-2">下载日志文件</h2>
<p>SAE将每天的日志文件都打包成tar.gz的格式，下载保存下来即可，文件名以<code>日期.tar.gz</code>命名</p>

<pre><code>log_files = list()

for down_url in response['data']:    
    file_name = re.compile(r'\d{4}-\d{2}-\d{2}').findall(down_url)[0] + '.tar.gz'
    log_files.append(file_name)
    data = urllib2.urlopen(down_url).read()
    with open(file_name, "wb") as file:
        file.write(data)

print '[#] you got %d log files' % len(log_files)
</code></pre>

<h2 id="section-3">合并文件</h2>
<p>合并文件方式用trafile库解压缩每个文件，然后把文件内容附加到access_log下就可以了</p>

<pre><code># compress these files to access_log
access_log = open('access_log','w');

for log_file in log_files:
    tar = tarfile.open(log_file)
    log_name = tar.getnames()[0]
    tar.extract(log_name)
    # save to access_log
    data = open(log_name).read()
    access_log.write(data)
    os.remove(log_name)

print '[#] all file has writen to access_log'
</code></pre>

<h2 id="section-4">代码下载地址</h2>
<p><a href="https://github.com/suyan/Scripts/blob/master/Python/sae-log-download.py">github</a></p>

